package example_test

import (
	"fmt"
	"math"
	"math/rand"
	"os"
	"os/exec"
	"runtime"
	"runtime/debug"
	"sort"
	"strconv"
	"strings"
	"sync"
	"sync/atomic"
	"testing"
	"time"
)

func TestAPIPressure(t *testing.T) {
	// åœ¨æµ‹è¯•å¼€å§‹æ—¶è®°å½•åˆå§‹goroutineæ•°é‡
	startGoroutines := runtime.NumGoroutine()
	// åœ¨æµ‹è¯•å¼€å§‹æ—¶åˆå§‹åŒ–ç›‘æ§
	cpuMon := NewCPUMonitor()
	debug.SetGCPercent(20) // æ¿€è¿›GCç­–ç•¥ä¾¿äºè§‚å¯Ÿ

	const (
		concurrency = 100
		totalCalls  = 10000
		timeout     = 1500 * time.Millisecond // ä¼˜åŒ–ç‚¹ï¼šæ”¶ç´§è¶…æ—¶é˜ˆå€¼
	)

	var (
		latencies         = make([]time.Duration, 0, totalCalls)
		failures          int32
		slowRequests      int32
		currentConcurrent int32
		peakConcurrent    int32
		statusCodes       = make(map[int]int)
		errorMessages     = make(map[string]int)
		dataTransferred   int64
		mu                sync.Mutex
		wg                sync.WaitGroup
	)

	// å†…å­˜é¢„çƒ­
	func() {
		tmp := make([][]byte, 100)
		for i := range tmp {
			tmp[i] = make([]byte, 1<<20) // 1MB
		}
	}()

	wg.Add(concurrency)
	startTime := time.Now()

	for i := 0; i < concurrency; i++ {
		go func() {
			defer wg.Done()
			for j := 0; j < totalCalls/concurrency; j++ {
				reqStart := time.Now()

				// å®æ—¶ç›‘æ§å¹¶å‘å³°å€¼
				curr := atomic.AddInt32(&currentConcurrent, 1)
				if curr > atomic.LoadInt32(&peakConcurrent) {
					atomic.StoreInt32(&peakConcurrent, curr)
				}
				defer atomic.AddInt32(&currentConcurrent, -1)

				// æ‰§è¡Œè¯·æ±‚
				latency, code, err := mockAPICall(reqStart, timeout)

				mu.Lock()
				if err != nil {
					failures++
					// é”™è¯¯æ™ºèƒ½åˆ†ç±»ï¼ˆæ–°å¢ï¼‰
					errType := classifyError(err)
					errorMessages[errType]++
				} else {
					latencies = append(latencies, latency)
					if latency > 500*time.Millisecond { // è®°å½•æ…¢è¯·æ±‚
						atomic.AddInt32(&slowRequests, 1)
					}
					statusCodes[code]++
					dataTransferred += rand.Int63n(1024)
				}
				mu.Unlock()
			}
		}()
	}

	wg.Wait()
	duration := time.Since(startTime)

	// ç¡®ä¿GCå’ŒCPUç»Ÿè®¡åœ¨æµ‹è¯•ç»“æŸæ—¶ç«‹å³æ‰§è¡Œ
	runtime.GC() // å¼ºåˆ¶è§¦å‘GC

	// è·å–æœ€ç»ˆç³»ç»ŸçŠ¶æ€
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)

	// æ£€æµ‹goroutineæ³„æ¼
	endGoroutines := runtime.NumGoroutine()
	leakThreshold := 5 // å…è®¸çš„goroutineæ³¢åŠ¨é˜ˆå€¼
	goroutineLeak := (endGoroutines - startGoroutines) > leakThreshold

	PrintEnhancedReport(t, TestResult{
		Concurrency:     concurrency,
		TotalCalls:      totalCalls,
		Duration:        duration,
		Failures:        failures,
		SlowRequests:    slowRequests,
		Latencies:       latencies,
		StatusCodes:     statusCodes,
		ErrorMessages:   errorMessages,
		DataTransferred: dataTransferred,
		PeakConcurrent:  peakConcurrent,
		GCNum:           getGCNum(),
		CPUUsage:        cpuMon.Usage(),
		Goroutines:      runtime.NumGoroutine(),        // æ–°å¢
		MemAllocMB:      float64(memStats.Alloc) / 1e6, // å­—èŠ‚è½¬MB
		GoroutineLeak:   goroutineLeak,
		StartGoroutines: startGoroutines,
	})
}

// æ™ºèƒ½é”™è¯¯åˆ†ç±»ï¼ˆæ–°å¢ï¼‰
func classifyError(err error) string {
	switch {
	case strings.Contains(err.Error(), "timeout"):
		return "timeout"
	case strings.Contains(err.Error(), "connection refused"):
		return "connection_error"
	default:
		return "unknown_error"
	}
}

// æ¨¡æ‹ŸAPIè°ƒç”¨ï¼ˆå®é™…æ›¿æ¢ä¸ºçœŸå®é€»è¾‘ï¼‰
func mockAPICall(reqStart time.Time, timeout time.Duration) (latency time.Duration, code int, err error) {
	defer func() { latency = time.Since(reqStart) }()

	// æ¨¡æ‹Ÿæ›´çœŸå®çš„å»¶è¿Ÿåˆ†å¸ƒï¼ˆä¼˜åŒ–ç‚¹ï¼‰
	baseDelay := time.Duration(30+rand.Intn(70)) * time.Millisecond
	additionalDelay := time.Duration(rand.Float64()*600) * time.Millisecond

	// æ¨¡æ‹Ÿ10%é”™è¯¯ç‡ï¼ˆå«ä¸åŒç±»å‹é”™è¯¯ï¼‰
	if rand.Float32() < 0.1 {
		switch rand.Intn(3) {
		case 0:
			time.Sleep(timeout + 100*time.Millisecond)
			return 0, 500, fmt.Errorf("timeout at %v", reqStart.Format("15:04:05.000"))
		case 1:
			return 0, 502, fmt.Errorf("connection refused")
		default:
			return 0, 503, fmt.Errorf("service unavailable")
		}
	}

	time.Sleep(baseDelay + additionalDelay)
	return 0, 200, nil
}

// TestResult å¢å¼ºç‰ˆæµ‹è¯•ç»“æœç»“æ„ä½“
type TestResult struct {
	Concurrency     int
	TotalCalls      int
	Duration        time.Duration
	Failures        int32
	SlowRequests    int32 // æ…¢è¯·æ±‚è®¡æ•°
	Latencies       []time.Duration
	StatusCodes     map[int]int
	ErrorMessages   map[string]int
	DataTransferred int64
	PeakConcurrent  int32   // å³°å€¼å¹¶å‘
	GCNum           uint32  // GCæ¬¡æ•°
	CPUUsage        float64 // CPUä½¿ç”¨ç‡ç™¾åˆ†æ¯”
	Goroutines      int     // æ–°å¢ï¼šå½“å‰goroutineæ•°é‡
	MemAllocMB      float64 // æ–°å¢ï¼šå†…å­˜åˆ†é…é‡(MB)
	GoroutineLeak   bool    // æ–°å¢ï¼šgoroutineæ³„æ¼æ ‡è®°
	StartGoroutines int     // æ–°å¢ï¼šæµ‹è¯•å¼€å§‹æ—¶çš„goroutineæ•°é‡
}

// PrintEnhancedReport å¢å¼ºç‰ˆæµ‹è¯•æŠ¥å‘Š
func PrintEnhancedReport(t *testing.T, result TestResult) {
	// åŸºç¡€æŒ‡æ ‡è®¡ç®—
	qps := float64(result.TotalCalls) / result.Duration.Seconds()
	successRate := float64(result.TotalCalls-int(result.Failures)) / float64(result.TotalCalls) * 100

	// å»¶è¿Ÿç»Ÿè®¡
	avg := avgLatency(result.Latencies)
	p50 := percentile(result.Latencies, 0.5)
	p90 := percentile(result.Latencies, 0.9)
	p99 := percentile(result.Latencies, 0.99)
	max := maxLatency(result.Latencies)
	min := minLatency(result.Latencies)

	// å¸¦å®½è®¡ç®—
	throughput := float64(result.DataTransferred) / result.Duration.Seconds()

	// å¯è§†åŒ–å»¶è¿Ÿåˆ†å¸ƒ
	histogram := buildLatencyHistogram(result.Latencies)

	leakStatus := "âœ… æ­£å¸¸"
	if result.GoroutineLeak {
		leakStatus = "âŒ æ£€æµ‹åˆ°æ³„æ¼"
	}

	t.Logf(`
ğŸš€ å¢å¼ºç‰ˆå‹åŠ›æµ‹è¯•æŠ¥å‘Š 
================================ 
ğŸ“Š åŸºç¡€æŒ‡æ ‡ 
-------------------------------- 
å¹¶å‘æ•°:       %d (req/goroutine)
æ€»è¯·æ±‚é‡:     %d (å¤±è´¥: %d)
æˆåŠŸç‡:       %.2f%%
æµ‹è¯•æ—¶é•¿:     %v 
QPS:         %.2f 
ååé‡:      %.2f MB/s 
æ…¢è¯·æ±‚(>500ms): %d (%.1f%%)
å³°å€¼å¹¶å‘:      %d
 
â±ï¸ å»¶è¿Ÿç»Ÿè®¡ (å•ä½: ms)
-------------------------------- 
å¹³å‡:        %v 
P50:        %v 
P90:        %v 
P99:        %v 
æœ€å¤§:        %v 
æœ€å°:        %v 
 
ğŸ“ˆ å»¶è¿Ÿåˆ†å¸ƒ 
%s 
 
ğŸ› ï¸ ç³»ç»ŸæŒ‡æ ‡ 
-------------------------------- 
æ€»æ•°æ®é‡:    %s 
çŠ¶æ€ç åˆ†å¸ƒ:  %v
GCæ¬¡æ•°:     %d
CPUä½¿ç”¨ç‡:  %.4f%%
Goroutines: %d (åˆå§‹: %d) %s 
å†…å­˜åˆ†é…:    %.2f MB`,
		result.Concurrency,
		result.TotalCalls,
		result.Failures,
		successRate,
		result.Duration,
		qps,
		throughput/(1024*1024),
		result.SlowRequests,
		float64(result.SlowRequests)/float64(len(result.Latencies))*100,
		result.PeakConcurrent,

		formatDuration(avg),
		formatDuration(p50),
		formatDuration(p90),
		formatDuration(p99),
		formatDuration(max),
		formatDuration(min),

		histogram,

		formatBytes(result.DataTransferred),
		formatStatusCodes(result.StatusCodes),
		result.GCNum,
		result.CPUUsage,
		result.Goroutines,
		result.StartGoroutines,
		leakStatus,
		result.MemAllocMB,
	)

	// è¾“å‡ºé”™è¯¯æ‘˜è¦
	if len(result.ErrorMessages) > 0 {
		t.Logf("\nâŒ é”™è¯¯æ‘˜è¦:\n%s", formatErrors(result.ErrorMessages))
	}
}

// è·å–GCæ¬¡æ•°ï¼ˆå…¼å®¹Go 1.18+ï¼‰
func getGCNum() uint32 {
	// å¼ºåˆ¶è§¦å‘ä¸€æ¬¡GCç¡®ä¿ç»Ÿè®¡å‡†ç¡®
	debug.FreeOSMemory()

	var stats debug.GCStats
	debug.ReadGCStats(&stats)
	return uint32(stats.NumGC)
}

// CPUMonitor ç²¾ç¡®çš„CPUä½¿ç”¨ç‡ç›‘æ§
type CPUMonitor struct {
	startTime time.Time
	startCPU  uint64
}

func NewCPUMonitor() *CPUMonitor {
	return &CPUMonitor{
		startTime: time.Now(),
		startCPU:  getProcessCPUTime(),
	}
}

func (m *CPUMonitor) Usage() float64 {
	elapsed := time.Since(m.startTime).Seconds()
	cpuTime := float64(getProcessCPUTime() - m.startCPU)
	usage := (cpuTime / elapsed) * 100 / float64(runtime.NumCPU())
	return math.Min(100, math.Max(0, usage)) // é™åˆ¶åœ¨0-100%èŒƒå›´å†…
}

// è·å–è¿›ç¨‹ç´¯è®¡CPUæ—¶é—´ï¼ˆçº³ç§’ï¼‰
func getProcessCPUTime() uint64 {
	switch runtime.GOOS {
	case "linux", "darwin":
		cmd := exec.Command("ps", "-o", "time=", "-p", strconv.Itoa(os.Getpid()))
		out, err := cmd.Output()
		if err != nil {
			return 0
		}
		parts := strings.Split(strings.TrimSpace(string(out)), ":")
		if len(parts) == 3 {
			h, _ := strconv.Atoi(parts[0])
			m, _ := strconv.Atoi(parts[1])
			s, _ := strconv.Atoi(parts[2])
			return uint64(h*3600+m*60+s) * 1e9
		}
	case "windows":
		cmd := exec.Command("wmic", "process", "where",
			"processid="+strconv.Itoa(os.Getpid()), "get", "KernelModeTime,UserModeTime")
		out, err := cmd.Output()
		if err != nil {
			return 0
		}
		lines := strings.Split(string(out), "\n")
		if len(lines) >= 2 {
			times := strings.Fields(lines[1])
			if len(times) == 2 {
				kernel, _ := strconv.ParseUint(times[0], 10, 64)
				user, _ := strconv.ParseUint(times[1], 10, 64)
				return (kernel + user) * 100 // è½¬æ¢ä¸ºçº³ç§’
			}
		}
	}
	return 0
}

// æ–°å¢è¾…åŠ©å‡½æ•°
func maxLatency(durations []time.Duration) time.Duration {
	if len(durations) == 0 {
		return 0
	}
	max := durations[0]
	for _, d := range durations {
		if d > max {
			max = d
		}
	}
	return max
}

func minLatency(durations []time.Duration) time.Duration {
	if len(durations) == 0 {
		return 0
	}
	min := durations[0]
	for _, d := range durations {
		if d < min {
			min = d
		}
	}
	return min
}

// æ„å»ºå»¶è¿Ÿç›´æ–¹å›¾
func buildLatencyHistogram(durations []time.Duration) string {
	if len(durations) == 0 {
		return "æ— å»¶è¿Ÿæ•°æ®"
	}

	buckets := []time.Duration{
		0, 10 * time.Millisecond, 50 * time.Millisecond,
		100 * time.Millisecond, 200 * time.Millisecond,
		500 * time.Millisecond, 1 * time.Second,
		2 * time.Second, 5 * time.Second,
	}

	counts := make([]int, len(buckets))
	for _, d := range durations {
		for i := len(buckets) - 1; i >= 0; i-- {
			if d >= buckets[i] {
				counts[i]++
				break
			}
		}
	}

	var sb strings.Builder
	total := len(durations)
	for i := 0; i < len(buckets)-1; i++ {
		percentage := float64(counts[i]) / float64(total) * 100
		sb.WriteString(fmt.Sprintf("%6s-%-6s | %-60s %.1f%%\n",
			formatDuration(buckets[i]),
			formatDuration(buckets[i+1]),
			strings.Repeat("â–ˆ", int(percentage/2)),
			percentage))
	}

	return sb.String()
}

// æ ¼å¼åŒ–å·¥å…·å‡½æ•°
func formatDuration(d time.Duration) string {
	return fmt.Sprintf("%.2fms", float64(d.Microseconds())/1000)
}

func formatBytes(b int64) string {
	const unit = 1024
	if b < unit {
		return fmt.Sprintf("%d B", b)
	}
	div, exp := int64(unit), 0
	for n := b / unit; n >= unit; n /= unit {
		div *= unit
		exp++
	}
	return fmt.Sprintf("%.1f %cB", float64(b)/float64(div), "KMGTPE"[exp])
}

func formatStatusCodes(codes map[int]int) string {
	var sb strings.Builder
	for code, count := range codes {
		sb.WriteString(fmt.Sprintf("%d: %d, ", code, count))
	}
	return strings.TrimSuffix(sb.String(), ", ")
}

func formatErrors(errors map[string]int) string {
	var sb strings.Builder
	for msg, count := range errors {
		sb.WriteString(fmt.Sprintf("  - %s (å‡ºç° %d æ¬¡)\n", msg, count))
	}
	return sb.String()
}

// avgLatency è®¡ç®—å¹³å‡å»¶è¿Ÿ
func avgLatency(durations []time.Duration) time.Duration {
	if len(durations) == 0 {
		return 0
	}
	var sum time.Duration
	for _, d := range durations {
		sum += d
	}
	return sum / time.Duration(len(durations))
}

// percentile è®¡ç®—ç™¾åˆ†ä½å»¶è¿Ÿ
func percentile(durations []time.Duration, p float64) time.Duration {
	if len(durations) == 0 {
		return 0
	}

	// æ’åºå»¶è¿Ÿæ•°æ®
	sort.Slice(durations, func(i, j int) bool {
		return durations[i] < durations[j]
	})

	// è®¡ç®—ç™¾åˆ†ä½ä½ç½®ï¼ˆçº¿æ€§æ’å€¼ï¼‰
	k := float64(len(durations)-1) * p
	floor := int(k)
	ceil := floor + 1

	if ceil >= len(durations) {
		return durations[floor]
	}

	weight := k - float64(floor)
	return time.Duration(float64(durations[floor])*(1-weight) + float64(durations[ceil])*weight)
}
